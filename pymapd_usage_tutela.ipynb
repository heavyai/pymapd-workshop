{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using OmniSci Pymapd API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pymapd (https://github.com/omnisci/pymapd)is the python DB API compliant interface for OmniSci. \n",
    "\n",
    "Packages are available on conda-forge and PyPI:\n",
    "conda install -c conda-forge pymapd\n",
    "pip install pymapd\n",
    "\n",
    "To install cudf for GPU Dataframe support (conda-only):\n",
    "conda install -c nvidia/label/cuda10.0 -c rapidsai/label/cuda10.0 -c numba -c conda-forge -c defaults cudf=0.6 pymapd python=3.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import csv\n",
    "import string\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pymapd import connect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to connect to the OmniSci database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the OmniSci database\n",
    "def connect_to_omnisci(str_user, str_password, str_host, str_dbname, isCloud):\n",
    "  try:\n",
    "    if (isCloud):\n",
    "      connection = connect(user=str_user, password=str_password, host=str_host, dbname=str_dbname, port=443, protocol='https')\n",
    "    else:\n",
    "      connection = connect(user=str_user, password=str_password, host=str_host, dbname=str_dbname, port=6274)\n",
    "  except Exception as ex:\n",
    "    template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "    message = template.format(type(ex).__name__, ex.args)\n",
    "    print(message)\n",
    "    if 'OmniSci Core not ready, try again' in message:\n",
    "      print(\"Set connection to RETRY!\")\n",
    "      connection = \"RETRY\"\n",
    "    else:\n",
    "      connection = \"ERROR\"\n",
    "  return connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call connect function passing the following arguments:\n",
    "user = mapd,\n",
    "password = HyperInteractive,\n",
    "host = localhost,\n",
    "database = mapd\n",
    "Also note the last argument which is flag to indicate whether you are connecting to OmniSci Cloud instance or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection(mapd://F0A7674FB728C4DE89A0:***@https://use2-api.mapd.cloud:443/mapd?protocol=https)\n"
     ]
    }
   ],
   "source": [
    "# Connect to OmniSci with 5 trys, this applies to OmniSci cloud instance which is paused during inactivity\n",
    "for i in range(5):\n",
    "  # connecting to a non-OmniSci Cloud instance\n",
    "  # connection = connect_to_omnisci(\"mapd\", \"HyperInteractive\", \"localhost\", \"mapd\", False)\n",
    "  # connecting to an OmniSci Cloud instance\n",
    "  # connection = connect_to_omnisci(\"F0A7xxxx\", \"fiNNxxxx\", \"use2-api.mapd.cloud\", \"mapd\", True)\n",
    "  connection = connect_to_omnisci(\"F0A7674FB728C4DE89A0\", \"fiNNiSG6YFZYac7Y9qLROCbbFRSif7L12BWfErSn\", \"use2-api.mapd.cloud\", \"mapd\", True)  \n",
    "  if connection == \"RETRY\":\n",
    "    # recommended time to sleep is 20 seconds before instance wakes up\n",
    "    time.sleep(20)\n",
    "    continue\n",
    "  if connection == \"ERROR\":\n",
    "    sys.exit(1)\n",
    "  print(connection)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List tables in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taxi_weather_tracts_factual\n",
      "nyc_trees_2015_683k\n",
      "flights_2008_7M\n",
      "cb_2017_us_county_20m\n",
      "veda_utility_lines\n",
      "utility_lines\n",
      "veda_citylots\n",
      "veda_sffacs_current\n",
      "veda_SFMTA_Bikeway_Network\n",
      "aaron_citylots\n",
      "btc_final_table5\n",
      "vs_Crimes_2001_to_present\n",
      "sf_citylots\n",
      "sf_facility\n",
      "sf_bikeway\n",
      "urbanlogiq_counts\n",
      "mapdcommunityeditiondl_allwebsitedata\n",
      "mapdcommunityeditiondl_singa\n",
      "worldcities\n",
      "all_countries\n",
      "tenM_small\n",
      "vs_mapd_downloads_seq\n",
      "dl_test1\n",
      "dl_test2\n",
      "CA2018CaliforniaOilandGasWellProduction_merged\n",
      "CA_2017CaliforniaOilandGasWellProduction_merged\n",
      "CaliforniaOilandGasWellProduction_merged\n",
      "vs_alldownloads\n",
      "taztest\n",
      "taztest2\n",
      "uber_movement_data2\n",
      "uber_movement_data1\n",
      "SanFrancisco_TAZ_data\n",
      "san_francisco_taz2\n",
      "bay_area_taz2\n",
      "NaturalGas_Pipelines_US_201804\n",
      "us_faults\n",
      "stats_load_omnisci_cloud\n",
      "vs_test_final\n",
      "probeVehicle_final\n",
      "vs_NaturalGas_Pipelines_US_201804\n",
      "nfl_flat\n",
      "nfl_flat_10games_10\n",
      "nfl_flat_10games\n",
      "temp_test_final\n",
      "vs_gas_production_us_2018\n",
      "test_final_small\n",
      "ta\n",
      "BigDataBowl_alldata\n",
      "ARW_weather\n",
      "ARW_weather2\n",
      "ARW_weather3\n",
      "ARW_bijou_watershed_buildings\n",
      "ARW_tahoe_lidar_hag\n",
      "iris\n",
      "up_pitches\n",
      "up_atbats\n",
      "up_player_names\n",
      "up_games\n",
      "mlb_data\n",
      "mlb_data1\n",
      "mlb_data2\n",
      "charter_fire_data\n",
      "charter_fire_inventory\n",
      "charter_firedata_feb24\n",
      "Woolsey_Fire_Perimeter_20181118\n",
      "vs_probeVehicle_v10\n",
      "RSU_OBU_routes\n",
      "NebulaXrecurringstartravel\n",
      "test_data\n",
      "probeVehicle\n",
      "Data_D4H19_AHT_Sept_2018\n",
      "southwest\n",
      "kinesis_test3\n",
      "kinesis_test4\n",
      "kinesis_test\n",
      "NaturalGas_Pipelines_US_201804_ver3\n",
      "NaturalGas_InterIntrastate_Pipelines_US_EIA\n",
      "NaturalGas_Pipelines_US_201804_ver11\n",
      "vs_gas_production\n",
      "vs_gas_production3\n",
      "vs_gas_production2\n",
      "natural_gas_production\n",
      "free_bike_status\n",
      "itcont_2020_20190616_20190808\n",
      "tutela_converge\n",
      "USA_Census_Populated_Places\n",
      "bike_status\n",
      "tutela_test2\n",
      "tutela_test\n",
      "tutela_test3\n"
     ]
    }
   ],
   "source": [
    "list_of_tables = connection.get_tables()\n",
    "print('\\n'.join(list_of_tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = 'tutela_converge'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get details of a preloaded table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ColumnDetails(name='LocalYear', type='SMALLINT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='LocalWeek', type='SMALLINT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Location_Geohash6', type='STR', nullable=True, precision=0, scale=0, comp_param=32), ColumnDetails(name='Latitude_Center', type='FLOAT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Longitude_Center', type='FLOAT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Location_City', type='STR', nullable=True, precision=0, scale=0, comp_param=32), ColumnDetails(name='Connection_Category', type='STR', nullable=True, precision=0, scale=0, comp_param=8), ColumnDetails(name='Device_SIMServiceProviderBrandName', type='STR', nullable=True, precision=0, scale=0, comp_param=16), ColumnDetails(name='Average_DownloadThroughput', type='FLOAT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Median_DownloadThroughput', type='FLOAT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Maximum_DownloadThroughput', type='FLOAT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Minimum_DownloadThroughput', type='FLOAT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Count_DownloadThroughput', type='INT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Average_UploadThroughput', type='FLOAT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Median_UploadThroughput', type='FLOAT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Maximum_UploadThroughput', type='FLOAT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Minimum_UploadThroughput', type='FLOAT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Count_UploadThroughput', type='INT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Average_Latency', type='FLOAT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Median_Latency', type='FLOAT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Maximum_Latency', type='FLOAT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Minimum_Latency', type='FLOAT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Count_Latency', type='INT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Average_Jitter', type='FLOAT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Median_Jitter', type='FLOAT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Maximum_Jitter', type='FLOAT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Minimum_Jitter', type='FLOAT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Count_Jitter', type='INT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Average_PacketLoss', type='FLOAT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Median_PacketLoss', type='FLOAT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Maximum_PacketLoss', type='FLOAT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Minimum_PacketLoss', type='FLOAT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Count_PacketLoss', type='INT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Average_SignalStrength', type='FLOAT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Median_SignalStrength', type='FLOAT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Maximum_SignalStrength', type='FLOAT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Minimum_SignalStrength', type='FLOAT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Count_SignalStrength', type='INT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Average_RSSNR', type='FLOAT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Median_RSSNR', type='FLOAT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Maximum_RSSNR', type='FLOAT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Minimum_RSSNR', type='FLOAT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Count_RSSNR', type='INT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Average_CQI', type='FLOAT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Median_CQI', type='FLOAT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Maximum_CQI', type='FLOAT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Minimum_CQI', type='FLOAT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Count_CQI', type='INT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Average_RSRQ', type='FLOAT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Median_RSRQ', type='FLOAT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Maximum_RSRQ', type='FLOAT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Minimum_RSRQ', type='FLOAT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Count_RSRQ', type='INT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='Number_of_Records', type='BIGINT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='SUM_ReceivedBytes', type='BIGINT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='SUM_TransmittedBytes', type='BIGINT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='UniqueCount_DeviceUID', type='INT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='ConsistentQualityExcellent', type='FLOAT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='ConsistentQualityBasic', type='FLOAT', nullable=True, precision=0, scale=0, comp_param=0)]\n"
     ]
    }
   ],
   "source": [
    "table_details = connection.get_table_details(table_name)\n",
    "print(table_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use SQL to select all flights by Southwest Airlines for a specified number of columns and save them to a Pandas dataframe if the number of rows returned is non-zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.61 s, sys: 0 ns, total: 4.61 s\n",
      "Wall time: 5.01 s\n",
      "20510\n",
      "(20510, 5)\n",
      "(4718, 5)\n",
      "    Week   Longitude   Latitude          City  AverageLatency\n",
      "5     11  -71.460571  41.767273      Cranston     3039.122070\n",
      "8     20 -122.557983  45.557556      Portland     3147.346924\n",
      "20    23  -71.021118  42.063904      Brockton     3525.406982\n",
      "30    32  -90.225220  38.800964  Spanish Lake     4533.570312\n",
      "34    33  -79.777222  40.448914   Monroeville     4460.000000\n"
     ]
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "SELECT LocalWeek, Longitude_Center, Latitude_Center,\n",
    "   Location_City, Average_Latency\n",
    "FROM tutela_converge \n",
    "WHERE Average_Latency > 3000\n",
    "\"\"\"      \n",
    "%time df = connection.execute(query)\n",
    "print(df.rowcount)\n",
    "if df.rowcount != 0:\n",
    "  mylist = list(df)\n",
    "  df2 = pd.DataFrame(mylist, columns=['Week', 'Longitude', 'Latitude', 'City', 'AverageLatency'])\n",
    "  print(df2.shape)\n",
    "  df2.dropna(inplace=True)\n",
    "  print(df2.shape)\n",
    "  print(df2.head())\n",
    "else:\n",
    "  print(\"No rows returned!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Week          City  AverageLatency  \\\n",
      "5     11      Cranston     3039.122070   \n",
      "8     20      Portland     3147.346924   \n",
      "20    23      Brockton     3525.406982   \n",
      "30    32  Spanish Lake     4533.570312   \n",
      "34    33   Monroeville     4460.000000   \n",
      "\n",
      "                                      CityPoint  \n",
      "5    POINT(-71.4605712890625 41.76727294921875)  \n",
      "8   POINT(-122.5579833984375 45.55755615234375)  \n",
      "20   POINT(-71.0211181640625 42.06390380859375)  \n",
      "30   POINT(-90.2252197265625 38.80096435546875)  \n",
      "34   POINT(-79.7772216796875 40.44891357421875)  \n",
      "(4718, 4)\n"
     ]
    }
   ],
   "source": [
    "df2['CityPoint'] = np.nan\n",
    "for idx, items in df2.iloc[0:].iterrows():\n",
    "    pointstring = \"POINT(\" + df2.loc[idx, 'Longitude'].astype(str) +\" \" + df2.loc[idx, 'Latitude'].astype(str) +\")\"\n",
    "    df2.loc[idx, 'CityPoint'] = pointstring\n",
    "df2 = df2.drop(columns=['Longitude', 'Latitude'])\n",
    "print(df2.head())\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE IF NOT EXISTS tutela_test (Week SMALLINT, City TEXT ENCODING DICT(8), AverageLatncy FLOAT, CityPoint GEOMETRY(POINT, 4326) ENCODING COMPRESSED(32))\n",
      "[ColumnDetails(name='Week', type='SMALLINT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='City', type='STR', nullable=True, precision=0, scale=0, comp_param=8), ColumnDetails(name='AverageLatncy', type='FLOAT', nullable=True, precision=0, scale=0, comp_param=0), ColumnDetails(name='CityPoint', type='POINT', nullable=True, precision=23, scale=4326, comp_param=32)]\n"
     ]
    }
   ],
   "source": [
    "create_table_str = 'CREATE TABLE IF NOT EXISTS tutela_test (Week SMALLINT, City TEXT ENCODING DICT(8), AverageLatncy FLOAT, CityPoint GEOMETRY(POINT, 4326) ENCODING COMPRESSED(32))'\n",
    "print(create_table_str)\n",
    "connection.execute(create_table_str)\n",
    "table_details = connection.get_table_details('tutela_test')\n",
    "print(table_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Week          City  AverageLatency  \\\n",
      "5     11      Cranston     3039.122070   \n",
      "8     20      Portland     3147.346924   \n",
      "20    23      Brockton     3525.406982   \n",
      "30    32  Spanish Lake     4533.570312   \n",
      "34    33   Monroeville     4460.000000   \n",
      "\n",
      "                                      CityPoint  \n",
      "5    POINT(-71.4605712890625 41.76727294921875)  \n",
      "8   POINT(-122.5579833984375 45.55755615234375)  \n",
      "20   POINT(-71.0211181640625 42.06390380859375)  \n",
      "30   POINT(-90.2252197265625 38.80096435546875)  \n",
      "34   POINT(-79.7772216796875 40.44891357421875)  \n",
      "(4718, 4)\n"
     ]
    }
   ],
   "source": [
    "df2['AverageLatency'] = pd.to_numeric(df2['AverageLatency'], downcast='float')\n",
    "df2['Week'] = pd.to_numeric(df2['Week'], downcast='integer')\n",
    "print(df2.head())\n",
    "print(df2.shape)\n",
    "df2.to_csv(\"tutela_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_table errors. load_table works if you drop the POINT column.\n",
    "#connection.load_table('tutela_test', df2, preserve_index=False)\n",
    "# load_table_rowwise no errors but does not do anything\n",
    "connection.load_table_rowwise('tutela_test', df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I manually loaded the table tutela_test from the CSV file that I crrated in the previous step. Run a geospatial query using the POINT column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 83 ms, sys: 0 ns, total: 83 ms\n",
      "Wall time: 844 ms\n",
      "404\n",
      "(404, 3)\n",
      "(404, 3)\n",
      "              City  AverageLatency    Distance\n",
      "0        Lexington     3066.285400  610.984314\n",
      "1           Selden     3557.372559  610.984314\n",
      "2  Massapequa Park     3730.742676  610.984314\n",
      "3       Park Ridge     3700.766846  610.984314\n",
      "4        Oceanside     3010.862549  610.984314\n"
     ]
    }
   ],
   "source": [
    "#AND ST_Distance(CAST(A.CityPoint as GEOGRAPHY), CAST(B.CityPoint as GEOGRAPHY)) < 1000\n",
    "query = f\"\"\"\n",
    "SELECT A.City, A.AverageLatency, ST_Distance(CAST(A.CityPoint as GEOGRAPHY), CAST(B.CityPoint as GEOGRAPHY)) \n",
    "FROM tutela_test A, tutela_test B \n",
    "WHERE A.AverageLatency > 3000\n",
    "AND B.AverageLatency > 3000 \n",
    "AND ST_Distance(CAST(A.CityPoint as GEOGRAPHY), CAST(B.CityPoint as GEOGRAPHY)) BETWEEN 1 AND 1000\n",
    "\"\"\"      \n",
    "%time df = connection.execute(query)\n",
    "print(df.rowcount)\n",
    "if df.rowcount != 0:\n",
    "  mylist = list(df)\n",
    "  df2 = pd.DataFrame(mylist, columns=['City', 'AverageLatency', 'Distance'])\n",
    "  print(df2.shape)\n",
    "  df2.dropna(inplace=True)\n",
    "  print(df2.shape)\n",
    "  print(df2.head())\n",
    "else:\n",
    "  print(\"No rows returned!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
